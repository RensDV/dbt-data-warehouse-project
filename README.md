# üèóÔ∏è dbt Data Warehouse Project

This project is a modernized, modular **data transformation pipeline** built with [dbt](https://docs.getdbt.com) (Data Build Tool) and SQL. It simulates a realistic business scenario using customer and sales datasets. The pipeline follows a **multi-layer architecture** (Bronze ‚Üí Silver ‚Üí Gold) and runs on **Azure SQL Database**.

---

## ‚ö° Quickstart

1. Clone the repo
   ```bash
   git clone https://github.com/yourusername/data_warehouse_dbt.git
   cd data_warehouse_dbt
   ```

2. Create and activate a virtual env  
   ```bash
   python -m venv .venv
   source .venv/bin/activate   # Mac/Linux
   .venv\Scripts\activate      # Windows
   ```

3. Install dependencies  
   ```bash
   pip install -r requirements.txt
   ```

4. Set environment variables (adjust values for your Azure SQL Database):  
   ```bash
   export DBT_USER=your_user
   export DBT_PASSWORD=your_password
   export DBT_HOST=your_server.database.windows.net
   export DBT_DB=DataWarehouse
   export DBT_SCHEMA=dev
   ```

5. Test your connection  
   ```bash
   dbt debug
   ```

6. Load seed data & build pipeline  
   ```bash
   dbt seed
   dbt run
   dbt test
   ```

7. Explore documentation site  
   ```bash
   dbt docs generate && dbt docs serve
   ```

---

## üßæ Versions Tested

- Python: 3.11.6
- dbt-core: 1.10.9  
- dbt-sqlserver: 1.9.0  

(Confirm locally with `dbt --version`.)

---

## üì¶ Project Structure

```
data_warehouse_dbt/
‚îú‚îÄ‚îÄ models/                 # Core transformation logic
‚îÇ   ‚îú‚îÄ‚îÄ bronze/             # Raw ingested data (from seeds)
‚îÇ   ‚îú‚îÄ‚îÄ silver/             # Cleaned, structured data
‚îÇ   ‚îî‚îÄ‚îÄ gold/               # Business-ready analytics
‚îú‚îÄ‚îÄ seeds/                  # Source CSV data (crm_cust_info, crm_sales_details, etc.)
‚îú‚îÄ‚îÄ macros/                 # Reusable macros
‚îú‚îÄ‚îÄ dbt_project.yml         # Project config
‚îú‚îÄ‚îÄ profiles.yml            # dbt profile (uses env vars for credentials)
‚îú‚îÄ‚îÄ requirements.txt        # Python dependencies
‚îú‚îÄ‚îÄ README.md               # This file
‚îî‚îÄ‚îÄ .gitignore              # Ignore .venv, target/, logs/, dbt_packages/
```

---

## üõ†Ô∏è Configuration

Your `profiles.yml` references environment variables for credentials and schema:

```yaml
my_azure_project:
  target: dev
  outputs:
    dev:
      type: sqlserver
      server: "{{ env_var('DBT_HOST') }}"
      port: 1433
      database: "{{ env_var('DBT_DB') }}"
      schema: "{{ env_var('DBT_SCHEMA') }}"
      user: "{{ env_var('DBT_USER') }}"
      password: "{{ env_var('DBT_PASSWORD') }}"
      encrypt: true
      trust_cert: true
```

---

## üìä Data Pipeline Overview

### üü´ Bronze Layer
- Raw ingestion from `seeds/` CSVs (e.g., `crm_cust_info`, `crm_sales_details`)  
- Minimal transformations: renaming, timestamps  

### ü™ô Silver Layer
- Cleansing & normalization  
- Deduplication, null handling, parsing  
- Ready for business joins  

### ü•á Gold Layer
- Business-ready fact and dimension tables  
- Example outputs:  
  - `fact_sales`  
  - `dim_customers`  
  - `dim_products`  
- Optimized for BI/analytics tools  

---

## üìê Modeling Philosophy

- Clear **Bronze ‚Üí Silver ‚Üí Gold** separation for transparency and lineage  
- Reusable logic via **macros**  
- **Tests + docs** stored alongside models for reproducibility  
- Naming conventions: `bronze_*`, `silver_*`, `dim_*`, `fact_*`  

---

## üìö Useful dbt Commands

```bash
# Build only the silver layer
dbt run --select silver/

# Force full refresh
dbt run --full-refresh

# Run tests
dbt test

# Debug connection
dbt debug
```

---

## üîç Testing & Documentation

- Tests live in `schema.yml` files (examples: `unique`, `not_null`)  
- Document models with `description:` fields  
- Generate & serve interactive documentation:  
  ```bash
  dbt docs generate
  dbt docs serve
  ```

---

## üìä Optional BI Integration

Gold models are accessible directly in **Power BI** using the SQL Server connector.  

Example visuals:
- Sales trends by product and customer  
- Country segmentation and sales volume  

---

## üß† Architecture Trade-offs

| Design Choice                  | Benefit                                 | Trade-off                                |
|--------------------------------|-----------------------------------------|------------------------------------------|
| Azure SQL instead of Data Lake | Easier setup, familiar SQL workflow     | Limited scalability for very large data   |
| SQL-only dbt transformations   | Simpler onboarding                     | No advanced ML/streaming capabilities    |
| Seeds ‚Üí Bronze ‚Üí Silver ‚Üí Gold | Transparent lineage, modular            | More verbose than direct ELT              |
| dbt `view` materializations    | Easy to inspect logic in DB             | Potentially slower queries on large data  |

---

## üôå Credits

Built by [Rens De Vent](https://github.com/RensDV) ‚Äî Data Engineer & Digital Nomad.  

> Demo / learning project. Fork ‚≠ê, explore, and adapt!


